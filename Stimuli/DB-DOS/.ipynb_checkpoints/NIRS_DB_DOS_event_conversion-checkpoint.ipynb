{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os, shutil\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../..')\n",
    "from preprocessing.scripts import argParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "nirs_dir = \"/data/perlman/moochie/analysis/CARE/NIRS_data_clean/\"\n",
    "psypy_dir = \"/data/perlman/moochie/study_data/CARE/task_data/DB_DOS/\"\n",
    "ex_subs = []\n",
    "participant_num_len = 5\n",
    "sample_rate = 7.81250\n",
    "n_blocks = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nirs_session_dirs = [os.path.split(d)[0] for d in glob(\n",
    "    nirs_dir+\"**/*_probeInfo.mat\",\n",
    "    recursive=True) \\\n",
    "    if d.strip(nirs_dir).strip(\"/\")[:participant_num_len] not in ex_subs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test line1: 114\t1\t0\t0\t0\t0\t0\t0\t0\n",
      "\n",
      "Wrote: /data/perlman/moochie/analysis/CARE/NIRS_data_clean/50502/V0/50502_V0_fNIRS/new_stims.txt\n"
     ]
    }
   ],
   "source": [
    "for ses in nirs_session_dirs[:1]:\n",
    "    # should always work, even with multiple-runs. \n",
    "    # TODO remember that these exist, where 2 runs are collected\n",
    "    # for the same dyad of parent/child, for unknown reason. \n",
    "    # potentially check for truncated run while parsing this data in other\n",
    "    # mne processing software\n",
    "    \n",
    "    og_evt = glob(ses+\"/*.evt\")\n",
    "    if len(og_evt) != 1:\n",
    "        print(\"Error: found\", len(og_evt), \"evt files for the given sub / visit.\")\n",
    "        continue\n",
    "    else:\n",
    "        og_evt = og_evt[0]\n",
    "    \n",
    "    f = open(og_evt, 'r')\n",
    "    line1 = f.readline()\n",
    "    print(\"test line1:\", line1)\n",
    "    \n",
    "    NSstim1_t = line1.split('\\t')[0]\n",
    "    \n",
    "#     print(ses)\n",
    "    child_sub = ses.strip(nirs_dir).strip(\"/\")[:participant_num_len]\n",
    "#     print(child_sub)\n",
    "    visit_ID = ses.strip(nirs_dir).strip(\"/\")[participant_num_len+1:participant_num_len+3]\n",
    "#     print(visit_ID)\n",
    "    # looks like it's working!\n",
    "    \n",
    "    task_file = glob(join(psypy_dir, child_sub, visit_ID)+ \"/*.csv\")\n",
    "   \n",
    "    if len(task_file) != 1:\n",
    "        print(\"Error: found\", len(task_file), \"task files for the given sub / visit.\")\n",
    "        continue\n",
    "    else:\n",
    "        task_file = task_file[0]\n",
    "      \n",
    "    # df of psychopy csv output\n",
    "    df = pd.read_csv(task_file)\n",
    "    \n",
    "    stims = []\n",
    "    \n",
    "    # iterate through any column that has \"countdown\" and \".started\"\n",
    "    block_i = 0\n",
    "    for col in df.columns:\n",
    "        \n",
    "        # if we're dealing with a legitimate block column\n",
    "        if (\"intro_txt\" in col) and (\".stopped\" in col):\n",
    "\n",
    "            # then also generate the name of the corresponding stop column\n",
    "            block_name_str = col.strip(\"intro_txt\").strip(\".stopped\")\n",
    "            \n",
    "            stopcol = \"timeup_txt\"+block_name_str+\".started\"\n",
    "            \n",
    "            # store any non-NaN vals in the start and stop column (times)\n",
    "            starts = (df[~df[col].isnull()][col].astype(float) + 5).tolist()\n",
    "            stops = (df[~df[stopcol].isnull()][stopcol].astype(float)).tolist()\n",
    "            \n",
    "            if len(starts) != len(stops):\n",
    "                print(\"Unequal number of starts and stops. ses:\", ses, \"block_i\", block_i)\n",
    "                continue\n",
    "            \n",
    "            # if there are no starts already entered / outlines has length 1,\n",
    "            # then we know that the first start in our starts is the same as line1 trigger. \n",
    "            # meaning that is the reference point to which the time course of the psychopy\n",
    "            # file and the NIRS file will be aligned, again using the sample rate\n",
    "            # or, easily, if block_i == 1.\n",
    "            \n",
    "            # append to stims with tuples of (time, evt_stim_col)\n",
    "            for i in range(len(starts)):\n",
    "                stims.append((starts[i], block_i))\n",
    "                stims.append((stops[i], 7))\n",
    "            \n",
    "            if block_i == 0:\n",
    "                PSstim1_t = starts[0]\n",
    "                stims.pop(0)\n",
    "                \n",
    "            converted_stims = []\n",
    "            for (time, val) in stims:\n",
    "                converted_stims.append((\n",
    "                    timeconvert_psychopy_to_nirstar(\n",
    "                        float(sample_rate),\n",
    "                        float(NSstim1_t),\n",
    "                        float(PSstim1_t),\n",
    "                        float(time)),\n",
    "                    val))\n",
    "            \n",
    "            block_i += 1\n",
    "        \n",
    "        # if we're not dealing with a legitimate column, we can just keep iterating\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    output_lines = [line1]\n",
    "    \n",
    "    for (stim_time, stim_col) in converted_stims:\n",
    "        evts = [0]*8\n",
    "        evts[stim_col]=1\n",
    "        \n",
    "        line = str(round(stim_time))\n",
    "        for evt_col in evts:\n",
    "            line += \"\\t\"\n",
    "            line += str(evt_col)\n",
    "        line += \"\\n\"\n",
    "            \n",
    "        output_lines.append(line)\n",
    "        \n",
    "    f = open(join(ses, \"new_eve.txt\"), 'w')\n",
    "    \n",
    "    for line in output_lines:\n",
    "        f.write(line)\n",
    "    \n",
    "    print(\"Wrote:\", join(ses, \"new_eve.txt\"))\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeconvert_psychopy_to_nirstar(\n",
    "    sample_rate,\n",
    "    NSstim1_t,\n",
    "    PSstim1_t,\n",
    "    PSevent_t):\n",
    "    \n",
    "    NSevent_t = NSstim1_t + (PSevent_t - PSstim1_t) * sample_rate\n",
    "    return NSevent_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRIenv",
   "language": "python",
   "name": "mrienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
